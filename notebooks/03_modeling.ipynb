{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Modeling & Interpretation\n",
    "This notebook handles model training, artifact generation, and validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Ensure project root is in path for src imports\n",
    "sys.path.append('..')\n",
    "from src.features import add_engineered_features\n",
    "from src.evaluation import generate_shap_plots\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "os.makedirs('../reports', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train Dummy Model for Pipeline Validation\n",
    "We fit a small model using the synthetic dataset to generate necessary `.pkl` artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define processing columns\n",
    "numeric_features = ['income', 'loan_amount', 'loan_duration_months', 'credit_score', 'age', 'previous_defaults', 'debt_to_income', 'monthly_payment']\n",
    "categorical_features = ['employment_type']\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('../data/raw/example.csv')\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Feature engineering\n",
    "X_eng = add_engineered_features(X)\n",
    "\n",
    "# Fit components\n",
    "X_proc = preprocessor.fit_transform(X_eng)\n",
    "model = XGBClassifier(n_estimators=10, random_state=42)\n",
    "model.fit(X_proc, y)\n",
    "\n",
    "# Persist artifacts\n",
    "joblib.dump(preprocessor, '../models/preprocessor.pkl')\n",
    "joblib.dump(model, '../models/final_model.pkl')\n",
    "\n",
    "print(\"Success: Model and preprocessor saved to models/ directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Unit Tests\n",
    "Ensuring the saved model meets the project requirements by running `test_model.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Triggering pytest for model validation...\")\n",
    "!python -m pytest ../tests/test_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Interpretation (SHAP)\n",
    "Analyzing feature contributions using the generated model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "# Display Top 5 Global Importances\n",
    "importances = model.feature_importances_\n",
    "feat_importances = pd.Series(importances, index=feature_names)\n",
    "top_5 = feat_importances.nlargest(5).to_dict()\n",
    "\n",
    "print(\"Top 5 Global Drivers:\")\n",
    "for feat, val in top_5.items():\n",
    "    print(f\"{feat}: {val:.4f}\")\n",
    "\n",
    "joblib.dump(top_5, '../models/top_features.pkl')\n",
    "\n",
    "# Save summary plot\n",
    "generate_shap_plots(model, X_proc, feature_names, output_path='../reports/shap_summary.png')\n",
    "print(\"SHAP summary saved to reports/shap_summary.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}